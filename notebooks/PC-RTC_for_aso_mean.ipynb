{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f5064e2-5ec3-4be7-9041-f825ee38c249",
   "metadata": {},
   "source": [
    "# Download mean of multiple Sentinel-1 RTCs for each ASO raster\n",
    "Given an ASO raster, find and download 1) the most proximate in time S1 RTC product 2) a \"snow-off\" RTC product from the preceeding summer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a54fdc55-62d9-4c67-bb24-c213da49ed3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# based on exmaples from\n",
    "# https://planetarycomputer.microsoft.com/docs/tutorials/cloudless-mosaic-sentinel2/\n",
    "# https://planetarycomputer.microsoft.com/dataset/sentinel-2-l2a#Example-Notebook\n",
    "from pystac.extensions.eo import EOExtension as eo\n",
    "import pystac_client\n",
    "import planetary_computer\n",
    "import glob\n",
    "import rioxarray as rxr\n",
    "import re\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from shapely.geometry import box\n",
    "import odc.stac\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "import traceback\n",
    "import rasterio as rio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3045b36-213a-493d-9e95-845355ac1423",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rtc_for_aso_snowon_mean(aso_raster_fn):\n",
    "    time = pd.to_datetime(re.search(\"(\\d{4}\\d{2}\\d{2})\", aso_raster_fn).group())\n",
    "    week_before = (time - datetime.timedelta(weeks=2)).strftime('%Y-%m-%d')\n",
    "    week_after = (time + datetime.timedelta(weeks=2)).strftime('%Y-%m-%d')\n",
    "    time_of_interest = f'{week_before}/{week_after}'\n",
    "\n",
    "    aso_raster = rxr.open_rasterio(aso_raster_fn).squeeze()\n",
    "    aso_raster = aso_raster.where(aso_raster>=0, drop=True)\n",
    "    bounds_latlon = box(*aso_raster.rio.transform_bounds(\"EPSG:4326\"))\n",
    "\n",
    "    catalog = pystac_client.Client.open(\n",
    "    \"https://planetarycomputer.microsoft.com/api/stac/v1\",\n",
    "    modifier=planetary_computer.sign_inplace)\n",
    "\n",
    "    search = catalog.search(\n",
    "        collections=[\"sentinel-1-rtc\"],\n",
    "        intersects=bounds_latlon,\n",
    "        datetime=time_of_interest)\n",
    "\n",
    "    # Check how many items were returned\n",
    "    items = search.item_collection()\n",
    "\n",
    "    rtc_stac = odc.stac.load(items,chunks={\"x\": 2048, \"y\": 2048},resolution=50, groupby='sat:absolute_orbit')\n",
    "    print(f\"Returned {len(rtc_stac.time)} acquisitions\")\n",
    "    rtc_stac_clipped = rtc_stac.rio.clip_box(*bounds_latlon.bounds,crs=\"EPSG:4326\")\n",
    "\n",
    "    rel_orbits = [scene.properties['sat:relative_orbit'] for scene in items.items]\n",
    "    ac_times = [scene.properties['datetime'] for scene in items.items]\n",
    "    ac_times = [np.datetime64(item) for item in ac_times]\n",
    "\n",
    "    # clip to ASO extent\n",
    "    rtc_stac_clipped = rtc_stac_clipped.rio.reproject_match(aso_raster, resampling=rio.enums.Resampling.bilinear)\n",
    "\n",
    "    # limit to morning acquisitions\n",
    "    rtc_ds = rtc_stac_clipped.where(rtc_stac_clipped.time.dt.hour > 11, drop=True)\n",
    "    if 'vv' not in list(rtc_ds.keys()) or 'vh' not in list(rtc_ds.keys()):\n",
    "        print('missing polarization')\n",
    "        return None\n",
    "\n",
    "    if len(rtc_ds.time) == 0:\n",
    "        print('no morning acquisitions')\n",
    "        return None\n",
    "\n",
    "\n",
    "    # calculate percent vh coverage of each acquisition\n",
    "    perc_cover = (rtc_ds.vh > 0).sum(dim=['x', 'y'])/(rtc_ds.vh >= -1000000000).sum(dim=['x', 'y'])\n",
    "\n",
    "    # if multiple with full coverage, grab nearest in time with full coverage\n",
    "    if perc_cover.values.tolist().count(1) > 1:\n",
    "        print('total snow-on coverage available')\n",
    "        rtc_ds = rtc_ds.where(perc_cover == 1, drop=True).sortby('time')\n",
    "        rtc_ds = rtc_ds.sel(time=time, method='nearest')\n",
    "\n",
    "    # exit if no rasters have good vh coverage\n",
    "    elif perc_cover.max() < 0.01:\n",
    "        print('max vh coverage is < 1%--recommend skipping ASO raster')\n",
    "\n",
    "    # otherwise, grab max coverage \n",
    "    else:\n",
    "        if perc_cover.max() == 1:\n",
    "            print('total snow-on coverage available')\n",
    "        else: \n",
    "            print(f'{perc_cover.max().item()} snow-on coverage')\n",
    "        rtc_ds = rtc_ds.sel(time=perc_cover.idxmax())\n",
    "\n",
    "    # get relative orbit of scene\n",
    "    rel_orbit = rel_orbits[ac_times.index(rtc_ds.time)]\n",
    "\n",
    "    orbit_dict = {}\n",
    "    for i, orbit in enumerate(rel_orbits):\n",
    "        if orbit not in orbit_dict.keys():\n",
    "            orbit_dict[orbit] = [ac_times[i]]\n",
    "        else:\n",
    "            orbit_dict[orbit].append(ac_times[i])\n",
    "\n",
    "    rtc_ds = rtc_stac_clipped.where(rtc_stac_clipped.time.isin(orbit_dict[rel_orbit]), drop=True)\n",
    "\n",
    "    # take mean of all acquisitions\n",
    "    print(f'taking mean of {rtc_ds.time.size} snow-on rasters')\n",
    "    rtc_ds = rtc_ds.mean(dim='time', skipna=True)\n",
    "\n",
    "    rtc_ds = rtc_ds.compute()\n",
    "\n",
    "    # mask negative areas\n",
    "    rtc_ds = rtc_ds.where(rtc_ds.vh > 0, drop=True)\n",
    "    rtc_ds = rtc_ds.where(rtc_ds.vv > 0, drop=True)\n",
    "\n",
    "    #rtc_ds.to_netcdf(f'../data/S1_rtc_mean/S1_snow-on_orbit{rel_orbit}_for_{aso_raster_fn.split(\"/\")[-1][:-4]}.nc')\n",
    "    \n",
    "    return rel_orbit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16b1b845-18f4-4ab2-ae86-d930fd5ce9db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "aso_raster_fn = '/home/jovyan/crunchy-snow/data/ASO/ASO_50m_SD_cleaned/utm10n/ASO_50M_SD_SacramentoMcCloud_20230209_clean.tif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7f3af7f-63d2-4fab-9b49-17f1474abce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rtc_for_aso_snowoff_mean(aso_raster_fn, rel_orbit):\n",
    "    year = pd.to_datetime(re.search(\"(\\d{4}\\d{2}\\d{2})\", aso_raster_fn).group()).year\n",
    "    time = pd.to_datetime(f'{year-1}0910')\n",
    "    week_before = (time - datetime.timedelta(weeks=2)).strftime('%Y-%m-%d')\n",
    "    week_after = (time + datetime.timedelta(weeks=2)).strftime('%Y-%m-%d')\n",
    "    time_of_interest = f'{week_before}/{week_after}'\n",
    "\n",
    "    aso_raster = rxr.open_rasterio(aso_raster_fn).squeeze()\n",
    "    aso_raster = aso_raster.where(aso_raster>=0, drop=True)\n",
    "    bounds_latlon = box(*aso_raster.rio.transform_bounds(\"EPSG:4326\"))\n",
    "\n",
    "    catalog = pystac_client.Client.open(\n",
    "    \"https://planetarycomputer.microsoft.com/api/stac/v1\",\n",
    "    modifier=planetary_computer.sign_inplace)\n",
    "\n",
    "    search = catalog.search(\n",
    "        collections=[\"sentinel-1-rtc\"],\n",
    "        intersects=bounds_latlon,\n",
    "        datetime=time_of_interest)\n",
    "\n",
    "    # Check how many items were returned\n",
    "    items = search.item_collection()\n",
    "\n",
    "    rel_orbits = [scene.properties['sat:relative_orbit'] for scene in items.items]\n",
    "    ac_times = [scene.properties['datetime'] for scene in items.items]\n",
    "    ac_times = [np.datetime64(item) for item in ac_times]\n",
    "\n",
    "    rtc_stac = odc.stac.load(items,chunks={\"x\": 2048, \"y\": 2048},resolution=50, groupby='sat:absolute_orbit')\n",
    "    print(f\"Returned {len(rtc_stac.time)} acquisitions\")\n",
    "    rtc_stac_clipped = rtc_stac.rio.clip_box(*bounds_latlon.bounds,crs=\"EPSG:4326\")\n",
    "\n",
    "    orbit_dict = {}\n",
    "    for i, orbit in enumerate(rel_orbits):\n",
    "        if orbit not in orbit_dict.keys():\n",
    "            orbit_dict[orbit] = [ac_times[i]]\n",
    "        else:\n",
    "            orbit_dict[orbit].append(ac_times[i])\n",
    "\n",
    "    if rel_orbit not in orbit_dict.keys():\n",
    "        print('no acquisitons from same orbit, skipping')\n",
    "        return\n",
    "\n",
    "    rtc_stac_clipped = rtc_stac_clipped.where(rtc_stac_clipped.time.isin(orbit_dict[rel_orbit]), drop=True)\n",
    "\n",
    "    # clip to ASO extent\n",
    "    rtc_ds = rtc_stac_clipped.rio.reproject_match(aso_raster, resampling=rio.enums.Resampling.bilinear)\n",
    "\n",
    "    if 'vv' not in list(rtc_ds.keys()) or 'vh' not in list(rtc_ds.keys()):\n",
    "        print('missing polarization, skipping')\n",
    "        return\n",
    "    \n",
    "    if len(rtc_ds.time) == 0:\n",
    "        print('no morning acquisitions')\n",
    "        return \n",
    "\n",
    "    # calculate percent vh coverage of each acquisition\n",
    "    perc_cover = (rtc_ds.vh > 0).sum(dim=['x', 'y'])/(rtc_ds.vh >= -1000000000).sum(dim=['x', 'y'])\n",
    "    \n",
    "    # if multiple with full coverage, grab nearest in time with full coverage\n",
    "    if perc_cover.values.tolist().count(1) > 1:\n",
    "        print('total snow-on coverage available')\n",
    "\n",
    "    # exit if no rasters have good vh coverage\n",
    "    elif perc_cover.max() < 0.01:\n",
    "        print('max vh coverage is < 1%--recommend skipping ASO raster')\n",
    "        return\n",
    "    \n",
    "    else:\n",
    "        if perc_cover.max() == 1:\n",
    "            print('total snow-on coverage available')\n",
    "        else: \n",
    "            print(f'{perc_cover.max().item()} snow-on coverage')\n",
    "    \n",
    "    # take mean of all acquisitions\n",
    "    print(f'taking mean of {rtc_ds.time.size} snow-off rasters')\n",
    "    rtc_ds = rtc_ds.mean(dim='time', skipna=True)\n",
    "\n",
    "    rtc_ds = rtc_ds.compute()\n",
    "\n",
    "    # mask negative areas\n",
    "    rtc_ds = rtc_ds.where(rtc_ds.vh > 0, drop=True)\n",
    "    rtc_ds = rtc_ds.where(rtc_ds.vv > 0, drop=True)\n",
    "    \n",
    "    #rtc_ds.to_netcdf(f'../data/S1_rtc/S1_snow-off_{rtc_ds.time.dt.strftime(\"%Y%m%d\").item()}_for_{aso_raster_fn.split(\"/\")[-1][:-4]}.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6e99807-8fd3-4bdd-aa2a-44beed78015d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rtc_for_aso_all(dir_path):\n",
    "    raster_paths = glob.glob(f'{dir_path}/*/ASO_50M_SD*.tif')\n",
    "    for i, path in enumerate(raster_paths):\n",
    "        print(f'----\\nworking on {path.split(\"/\")[-1]}, {i+1}/{len(raster_paths)}\\n----')\n",
    "        \n",
    "        try:\n",
    "            relative_orbit = rtc_for_aso_snowon_mean(path)\n",
    "            if relative_orbit == None:\n",
    "                continue\n",
    "            rtc_for_aso_snowoff_mean(path, relative_orbit)\n",
    "        except Exception as exc:\n",
    "            print(traceback.format_exc())\n",
    "            print(exc)\n",
    "            print('encountered error, skipping')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57953403-83c7-49f9-9230-1006abc3d961",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      "working on ASO_50M_SD_BlueRiver_20230529_clean.tif, 1/252\n",
      "----\n",
      "Returned 4 acquisitions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2825/1392962745.py:29: DeprecationWarning: parsing timezone aware datetimes is deprecated; this will raise an error in the future\n",
      "  ac_times = [np.datetime64(item) for item in ac_times]\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/rasterio/warp.py:344: NotGeoreferencedWarning: Dataset has no geotransform, gcps, or rpcs. The identity matrix will be returned.\n",
      "  _reproject(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total snow-on coverage available\n",
      "taking mean of 2 snow-on rasters\n",
      "Returned 5 acquisitions\n",
      "total snow-on coverage available\n",
      "taking mean of 3 snow-off rasters\n",
      "----\n",
      "working on ASO_50M_SD_Animas_20210419_clean.tif, 2/252\n",
      "----\n",
      "Returned 7 acquisitions\n",
      "total snow-on coverage available\n",
      "taking mean of 2 snow-on rasters\n",
      "Returned 7 acquisitions\n",
      "total snow-on coverage available\n",
      "taking mean of 3 snow-off rasters\n",
      "----\n",
      "working on ASO_50M_SD_EastRiver_20230523_clean.tif, 3/252\n",
      "----\n",
      "Returned 8 acquisitions\n",
      "total snow-on coverage available\n",
      "taking mean of 1 snow-on rasters\n",
      "Returned 8 acquisitions\n",
      "total snow-on coverage available\n",
      "taking mean of 3 snow-off rasters\n",
      "----\n",
      "working on ASO_50M_SD_EastRiver_20220518_clean.tif, 4/252\n",
      "----\n",
      "Returned 5 acquisitions\n",
      "total snow-on coverage available\n",
      "taking mean of 2 snow-on rasters\n",
      "Returned 9 acquisitions\n",
      "total snow-on coverage available\n",
      "taking mean of 2 snow-off rasters\n",
      "----\n",
      "working on ASO_50M_SD_SouthPlatte_20230416_clean.tif, 5/252\n",
      "----\n",
      "Returned 9 acquisitions\n"
     ]
    }
   ],
   "source": [
    "dir_path = '/home/jovyan/crunchy-snow/data/ASO/ASO_50m_SD_cleaned'\n",
    "test = rtc_for_aso_all(dir_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
