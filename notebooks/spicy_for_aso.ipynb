{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "# download spicy products for ASO rasters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains functions to run spicy-snow for the region/date of each snow depth raster in a directory.\n",
    "\n",
    "NOTES:\n",
    "- Changed sentinel1.py in spicy to resample to 50 m pixel spacing (matching ASO) rather than default 90.\n",
    "- Changed user_dates.py to have start date on September 1 instead of August 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # install spicy-snow in the current Jupyter kernel\n",
    "# import sys\n",
    "# !{sys.executable} -m pip install spicy-snow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import spicy-snow functions and other required packages\n",
    "# depending on your environment, you may need to install some of these\n",
    "from spicy_snow.retrieval import retrieve_snow_depth\n",
    "from spicy_snow.IO.user_dates import get_input_dates\n",
    "import geopandas as gpd\n",
    "from pathlib import Path\n",
    "from shapely import geometry\n",
    "from glob import glob\n",
    "import rasterio as rio\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spicy_for_aso(dir_path):\n",
    "    '''\n",
    "    Run spicy for the extent and date of ASO rasters\n",
    "    '''\n",
    "    path_list = glob(f'{dir_path}/*ASO_50M_SD*.tif')\n",
    "    \n",
    "    for i, path in enumerate(path_list):\n",
    "        print(f'-------\\nworking on {path.split(\"/\")[-1]}, {i+1}/{len(path_list)}\\n-------')\n",
    "        # get bounding box from ASO raster\n",
    "        raster = rio.open(path)\n",
    "        gdf = gpd.GeoDataFrame({\"id\":1,\"geometry\":[geometry.box(*raster.bounds)]}, crs=raster.crs)\n",
    "        area = gdf.to_crs('4326').geometry.values[0]\n",
    "        \n",
    "        # get acquistion date from ASO raster\n",
    "        dates = get_input_dates(path.split('/')[-1].split('_')[-2])\n",
    "        \n",
    "        # define output directory and file name\n",
    "        site_name = path.split('/')[-1].split('_')[-3]\n",
    "        utm_zone = path.split('/')[-2]\n",
    "        out_nc = Path(f'..data/spicy/{utm_zone}/spicy_{site_name}_{dates[0]}_{dates[1]}.nc').expanduser()\n",
    "        \n",
    "        if os.path.exists(out_nc):\n",
    "            print('spicy-snow output already exists, skipping')\n",
    "            \n",
    "        else:\n",
    "            # run spicy-snow for ASO raster\n",
    "            spicy_ds = retrieve_snow_depth(area = area,\n",
    "                                           dates = dates, \n",
    "                                           work_dir = Path('/tmp/spicy/').expanduser(), \n",
    "                                           job_name = f'spicy_{site_name}_{dates[0]}_{dates[1]}',\n",
    "                                           existing_job_name = f'spicy_{site_name}_{dates[0]}_{dates[1]}',\n",
    "                                           debug=False,\n",
    "                                           outfp=out_nc)\n",
    "            \n",
    "            #!rm /tmp/spicy/tmp/S1*.tif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------\n",
      "working on ASO_50M_SD_Dolores_20210420_clean.tif, 1/8\n",
      "-------\n",
      "(spicy-snow spicy_snow.utils.spicy_logging INFO) Found 115 results\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Submitting s1 jobs: 100%|███████████████████████████████████████████████████| 115/115 [01:09<00:00,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(spicy-snow spicy_snow.utils.spicy_logging INFO) Watching 115 jobs. This may take a while...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc5b37bf328a4b8f8e60ca62325eb3fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/115 [timeout in 10800 s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading S1 images: 100%|██████████████████████████████████████████████| 115/115 [1:36:30<00:00, 50.35s/it]\n",
      "Combining Sentinel-1 dataArrays: 100%|██████████████████████████████████████| 115/115 [07:20<00:00,  3.83s/it]\n",
      "Downloading IMS snow-cover:  12%|█████▍                                        | 9/76 [00:31<04:12,  3.77s/it]"
     ]
    }
   ],
   "source": [
    "path = '/mnt/c/Users/qbren/Desktop/taco/projects/crunchy-snow/data/ASO/ASO_50m_SD_cleaned/utm12n'\n",
    "spicy_for_aso(path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:spicy] *",
   "language": "python",
   "name": "conda-env-spicy-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
